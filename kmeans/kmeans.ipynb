{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=60000)\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = 'dataset/train-images.idx3-ubyte'\n",
    "train_labels_path = 'dataset/train-labels.idx1-ubyte'\n",
    "test_images_path = 'dataset/t10k-images.idx3-ubyte'\n",
    "test_labels_path = 'dataset/t10k-labels.idx1-ubyte'\n",
    "\n",
    "def load_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "X_train = load_idx(train_images_path).reshape(60000, 784)\n",
    "y_train = load_idx(train_labels_path)\n",
    "X_test = load_idx(test_images_path).reshape(10000, 784)\n",
    "y_test = load_idx(test_labels_path)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 20)\n",
      "X_test shape: (10000, 20)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train_pca.shape)\n",
    "print('X_test shape:', X_test_pca.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.93258788, -312.67424419,  -24.51406838, ...,  308.5890876 ,\n",
       "         278.05128029,  163.27684841],\n",
       "       [1011.71837533, -294.85701741,  596.33954532, ...,   39.57384325,\n",
       "          52.96289747, -102.97723732],\n",
       "       [ -51.84960873,  392.17315428, -188.50976325, ..., -122.37998602,\n",
       "         -11.00721993, -435.3068495 ],\n",
       "       ...,\n",
       "       [-178.05344948,  160.07821073, -257.6130816 , ...,  -37.33350111,\n",
       "         101.97751982,  240.76596341],\n",
       "       [ 130.60607123,   -5.59193388,  513.85867477, ..., -141.95338899,\n",
       "         -75.06672135,  196.34573267],\n",
       "       [-173.43595135,  -24.71880663,  556.01890908, ...,  269.33091639,\n",
       "          93.14246603, -208.41044729]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, max_iter=100, tol=1e-4):\n",
    "    centroids = X[np.random.choice(len(X), k, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # calculate euclidean distances between each point and the centroids\n",
    "        distances = np.sqrt(((X[:, np.newaxis] - centroids)**2).sum(axis=2))\n",
    "        #Assign each point to the nearest centroid\n",
    "        clusters = np.argmin(distances, axis=1)\n",
    "        new_centroids = np.array([X[clusters == i].mean(axis=0) for i in range(k)])\n",
    "        \n",
    "        # convergence check if centroids change less than tolerance\n",
    "        if np.linalg.norm(new_centroids - centroids) < tol:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_consistency(labels, true_labels, k):\n",
    "    Qs = []\n",
    "    for i in range(k):\n",
    "        cluster_points = true_labels[labels == i]\n",
    "        mi = np.bincount(cluster_points).max()\n",
    "        Ni = len(cluster_points)\n",
    "        Qs.append(mi / Ni)\n",
    "    return np.mean(Qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster consistency for k=5: 0.3868197667130647\n",
      "Cluster consistency for k=10: 0.6008799260014361\n",
      "Cluster consistency for k=20: 0.7229718345385645\n",
      "Cluster consistency for k=40: 0.8181196634215381\n"
     ]
    }
   ],
   "source": [
    "k_values = [5, 10, 20, 40]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    centroids, clusters = kmeans(X_train_pca, k)\n",
    "    # print(clusters)\n",
    "    Q = cluster_consistency(clusters, y_train, k)\n",
    "    results[k] = Q\n",
    "    print(f\"Cluster consistency for k={k}: {Q}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
